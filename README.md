# my-trans

> ğŸ¤– **AI æ—¶ä»£å·²ç»æ¥ä¸´ï¼Œè§£æ”¾åŒæ‰‹ï¼**
> 
> æœ¬é¡¹ç›®ç”± [OpenCode](https://opencode.ai) åŸºäº **MiniMax-M2.1** æ¨¡å‹ç”Ÿæˆï¼Œå…¨ç¨‹ä½¿ç”¨ AI ååŠ©å¼€å‘ã€‚
> 
> è¿™æ˜¯ä¸€ä¸ªå…¨ AI é©±åŠ¨çš„é¡¹ç›®ï¼Œå±•ç¤ºäº† AI åœ¨å®é™…åº”ç”¨ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚

AI æ—¶ä»£å·²ç»æ¥ä¸´ï¼Œè§£æ”¾åŒæ‰‹ï¼

åŸºäº AI çš„è§†é¢‘å­—å¹•ç”Ÿæˆä¸ç¿»è¯‘å·¥å…·ï¼Œæ”¯æŒå¤šè¯­è¨€è‡ªåŠ¨æ£€æµ‹ï¼Œç”Ÿæˆä¸­æ–‡åŒè¯­å­—å¹•ã€‚

AI-powered video subtitle generation and translation tool. Supports automatic language detection for multilingual videos, generating Chinese bilingual subtitles.

---

## YouTube è§†é¢‘å­—å¹•ä¸€é”®ç”Ÿæˆ:

```bash
# 1. å®‰è£… yt-dlp
pip install yt-dlp

# 2. è®¾ç½®ä»£ç†å¹¶ä¸‹è½½è§†é¢‘ï¼ˆæœ€ä½³ç”»è´¨ï¼Œè‡ªåŠ¨åˆå¹¶ï¼‰
export http_proxy="http://192.168.124.3:7897"
export https_proxy="http://192.168.124.3:7897"
yt-dlp -o "%(title)s.%(ext)s" -f b --restrict-filenames "https://www.youtube.com/watch?v=xxxxx"

# 3. ç”¨ AI ç”Ÿæˆå­—å¹•ï¼ˆè‡ªåŠ¨æ£€æµ‹è¯­è¨€ï¼‰
python transcribe.py video.mp4

# 4. ç¿»è¯‘æˆä¸­æ–‡åŒè¯­å­—å¹•
python translate_vtt.py video.ass
```

# 3. ç¿»è¯‘æˆä¸­æ–‡åŒè¯­å­—å¹•
python translate_vtt.py video.ass
```

---

## AI åä½œ / AI Collaboration

| è§’è‰² / Role | å·¥å…· / Tool | è¯´æ˜ / Description |
|-----------|-------------|------------------|
| éœ€æ±‚ä¸å¼€å‘ / Requirement & Development | [OpenCode](https://opencode.ai) | AI ç¼–ç¨‹åŠ©æ‰‹ï¼ŒåŸºäº MiniMax-M2.1 æ¨¡å‹ |
| è¯­éŸ³è¯†åˆ« / Speech Recognition | [faster-whisper](https://github.com/SYSTRAN/faster-whisper) | OpenAI Whisper çš„ CTranslate2 ä¼˜åŒ–ç‰ˆ |
| ç¿»è¯‘å¼•æ“ / Translation Engine | [CTranslate2](https://github.com/OpenNMT/CTranslate2) | é«˜æ€§èƒ½ Transformer æ¨ç†å¼•æ“ |
| å¤šè¯­è¨€ç¿»è¯‘ / Multilingual Translation | [NLLB-200](https://huggingface.co/facebook/nllb-200-distilled-3.3B) | Meta AI 200+ è¯­è¨€ç¿»è¯‘æ¨¡å‹ |

> ğŸ’¡ **ä»æƒ³æ³•åˆ°å®ç°ï¼Œå…¨ç¨‹ç”± AI ååŠ©å®Œæˆ**  
> **From idea to implementation, all assisted by AI**

---

## æŠ€æœ¯æ¶æ„ / Technical Architecture

### æ ¸å¿ƒæ¨¡å‹ / Core Models

| åŠŸèƒ½ / Function | æ¨¡å‹ / Model | è¯´æ˜ / Description |
|----------------|-------------|-------------------|
| è¯­éŸ³è¯†åˆ« / Speech Recognition | [faster-whisper](https://github.com/SYSTRAN/faster-whisper) | OpenAI Whisper çš„ CTranslate2 ä¼˜åŒ–ç‰ˆ |
| ç¿»è¯‘ / Translation | [NLLB-200-3.3B](https://huggingface.co/facebook/nllb-200-distilled-3.3B) | Meta å¤šè¯­è¨€ç¿»è¯‘æ¨¡å‹ï¼Œæ”¯æŒ 200+ è¯­è¨€ |

### æŠ€æœ¯æ ˆ / Tech Stack

- **[faster-whisper](https://github.com/SYSTRAN/faster-whisper)**: åŸºäº CTranslate2 çš„ Whisper æ¨ç†åŠ é€Ÿ
- **[CTranslate2](https://github.com/OpenNMT/CTranslate2)**: é«˜æ€§èƒ½ Transformer æ¨ç†å¼•æ“
- **[transformers](https://huggingface.co/docs/transformers)**: Hugging Face æ¨¡å‹åº“

---

## æ¨¡å‹ä¸‹è½½ / Model Download

### ä½¿ç”¨ä¸‹è½½è„šæœ¬ (æ¨è / Recommended)

```bash
# è¿è¡Œä¸‹è½½è„šæœ¬ / Run download script
python download_models.py

# é€‰é¡¹ / Options:
#   1. ä¸‹è½½ faster-whisper æ¨¡å‹
#   2. ä¸‹è½½ NLLB ç¿»è¯‘æ¨¡å‹
#   3. ä¸‹è½½å…¨éƒ¨æ¨¡å‹
```

### 1. Whisper æ¨¡å‹ / Whisper Model

```bash
# ä½¿ç”¨ faster-whisper é»˜è®¤é…ç½®ï¼Œè‡ªåŠ¨ä¸‹è½½æ¨¡å‹ / Use faster-whisper default config, auto-download model
# æ¨¡å‹è·¯å¾„ / Model path: e:/cuda/faster-whisper-medium
```

### 2. NLLB ç¿»è¯‘æ¨¡å‹ / NLLB Translation Model

```bash
# æ–¹æ³•1: ä½¿ç”¨ä¸‹è½½è„šæœ¬ / Method 1: Use download script
python download_models.py

# æ–¹æ³•2: ä½¿ç”¨ huggingface-cli / Method 2: Use huggingface-cli
huggingface-cli download Derur/nllb-200-3.3B-ct2-float16 --local-dir E:/cuda/nllb-200-3.3B-ct2-float16 --local-dir-use-symlinks false
```

**æ¨¡å‹ä»‹ç» / Model Introduction:**

| é¡¹ç›® / Item | è¯´æ˜ / Description |
|------------|------------------|
| æ¨¡å‹ / Model | [Derur/nllb-200-3.3B-ct2-float16](https://huggingface.co/Derur/nllb-200-3.3B-ct2-float16) |
| æ¥æº / Source | ç¤¾åŒºé¢„è½¬æ¢æ¨¡å‹ / Community pre-converted model |
| åŸå§‹æ¨¡å‹ / Original Model | [facebook/nllb-200-distilled-3.3B](https://huggingface.co/facebook/nllb-200-distilled-3.3B) |
| é‡åŒ–æ–¹å¼ / Quantization | FP16 (Float16) |
| æ¨¡å‹å¤§å° / Size | ~6.5GB |
| è¯­è¨€æ•°é‡ / Languages | 200+ ç§è¯­è¨€ / languages |

**é‡åŒ–æ•ˆæœ / Quantization Effects:**

| é‡åŒ–æ–¹å¼ / Type | æ¨¡å‹å¤§å° / Size | æ˜¾å­˜å ç”¨ / VRAM | é€Ÿåº¦ / Speed | ç²¾åº¦æŸå¤± / Quality Loss |
|---------------|---------------|----------------|-------------|---------------------|
| FP32 | ~13GB | ~10GB | åŸºå‡† / Base | æ—  / None |
| FP16 | ~6.5GB | ~5GB | å¿« 1.5x | å‡ ä¹æ—  / Almost none |
| INT8 | ~3.3GB | ~3GB | å¿« 2-3x | ~1-2% |
| INT4 | ~1.7GB | ~2GB | å¿« 4x | ~3-5% |

**æ¨èé…ç½® / Recommended Config:**
- **FP16 (æœ¬é¡¹ç›®ä½¿ç”¨)**: æœ€ä½³å¹³è¡¡ï¼Œé€Ÿåº¦å¿«ã€ç²¾åº¦é«˜
- é€‚åˆ RTX 3080 (10GB) åŠä»¥ä¸Šæ˜¾å¡

åŸå§‹æ¨¡å‹ / Original Model:
- [facebook/nllb-200-distilled-3.3B](https://huggingface.co/facebook/nllb-200-distilled-3.3B)

---

## ç¯å¢ƒé…ç½® / Environment Setup

### Python ç‰ˆæœ¬ / Python Version
- Python 3.9+

### ä¾èµ–å®‰è£… / Dependencies Installation

```bash
# PyTorch (GPU) - Windows CUDA 11.8
pip install torch==2.7.1+cu118 torchvision==0.22.1+cu118 torchaudio==2.7.1+cu118 --index-url https://download.pytorch.org/whl/cu118

# æ ¸å¿ƒä¾èµ– / Core dependencies
pip install faster-whisper==1.2.1
pip install ctranslate2==4.7.1
pip install transformers==4.35.0
pip install huggingface_hub==0.16.4
pip install tokenizers==0.14.0
```

### å®Œæ•´å®‰è£…å‘½ä»¤ / Complete Installation Command

```bash
# 1. å®‰è£… PyTorch (GPU)
pip install torch==2.7.1+cu118 torchvision==0.22.1+cu118 torchaudio==2.7.1+cu118 --index-url https://download.pytorch.org/whl/cu118

# 2. å®‰è£…å…¶ä»–ä¾èµ–
pip install faster-whisper==1.2.1 ctranslate2==4.7.1 transformers==4.35.0 huggingface_hub==0.16.4 tokenizers==0.14.0
```

### éªŒè¯å®‰è£… / Verify Installation

```powershell
# æŸ¥çœ‹å·²å®‰è£…çš„ CUDA ç›¸å…³åŒ…
pip list | findstr cuda
```

è¾“å‡ºç¤ºä¾‹ / Output example:
```
torch              2.7.1+cu118
torchaudio         2.7.1+cu118
torchvision        0.22.1+cu118
ctranslate2        4.7.1
```

---

## ä½¿ç”¨æ–¹æ³• / Usage

### 1. ç”Ÿæˆè‹±æ–‡å­—å¹• / Generate English Subtitles

```bash
python transcribe.py video.mp4
```
è¾“å‡º / Output: `video.vtt` (è‹±æ–‡å­—å¹• / English subtitles)

### 2. ç¿»è¯‘ä¸ºåŒè¯­å­—å¹• / Translate to Bilingual Subtitles

```bash
python translate_vtt.py video.vtt
```
è¾“å‡º / Output: `video.bilingual.vtt` (åŒè¯­å­—å¹• / Bilingual subtitles)

### è‡ªåŠ¨è¯­è¨€æ£€æµ‹ / Auto Language Detection

æ”¯æŒè‡ªåŠ¨æ£€æµ‹å­—å¹•è¯­è¨€å¹¶ç¿»è¯‘ä¸ºä¸­æ–‡ï¼š

```bash
# è‡ªåŠ¨æ£€æµ‹è¯­è¨€å¹¶ç¿»è¯‘ä¸ºä¸­æ–‡åŒè¯­å­—å¹•
python translate_vtt.py video.vtt
```

æ”¯æŒçš„è¯­è¨€ / Supported Languages:

| è¯­è¨€ä»£ç  | Language | è¯´æ˜ / Description |
|---------|----------|-------------------|
| `ja` | Japanese | æ—¥è¯­ |
| `en` | English | è‹±è¯­ |
| `zh` | Chinese | ä¸­æ–‡ |
| `ko` | Korean | éŸ©è¯­ |
| `fr` | French | æ³•è¯­ |
| `de` | German | å¾·è¯­ |
| `es` | Spanish | è¥¿ç­ç‰™è¯­ |

### æ‰‹åŠ¨æŒ‡å®šè¯­è¨€ / Manual Language Selection

å¦‚éœ€æŒ‡å®šæºè¯­è¨€ï¼Œä½¿ç”¨ `--lang` å‚æ•°ï¼š

```bash
# æ—¥è¯­è§†é¢‘
python translate_vtt.py --lang=ja video.vtt

# éŸ©è¯­è§†é¢‘
python translate_vtt.py --lang=ko video.vtt

# è‹±è¯­è§†é¢‘
python translate_vtt.py --lang=en video.vtt
```

### æ‰¹é‡å¤„ç† / Batch Processing

```bash
# å¤šä¸ªè§†é¢‘ / Multiple videos
python transcribe.py video1.mp4 video2.mp4 video3.mp4
```

---

## è„šæœ¬è¯´æ˜ / Script Description

| è„šæœ¬ / Script | åŠŸèƒ½ / Function |
|-------------|--------------|
| `download_models.py` | ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ° / Download models to local |
| `transcribe.py` | ä½¿ç”¨ faster-whisper ç”Ÿæˆè‹±æ–‡å­—å¹• / Generate English subtitles with faster-whisper |
| `translate_vtt.py` | ä½¿ç”¨ CTranslate2+NLLB ç¿»è¯‘ä¸ºåŒè¯­å­—å¹• / Translate to bilingual subtitles with CTranslate2+NLLB |
| `translate_nllb_official.py` | å®˜æ–¹ transformers ç‰ˆæœ¬çš„ç¿»è¯‘è„šæœ¬ / Official transformers version translation script |

---

## æ€§èƒ½å¯¹æ¯” / Performance Comparison

| ç‰ˆæœ¬ / Version | é€Ÿåº¦ / Speed | è¯´æ˜ / Description |
|--------------|-------------|------------------|
| CTranslate2 (æ¨è / Recommended) | ~390ms/æ¡ | GPU åŠ é€Ÿï¼Œå…¼å®¹æ€§å¥½ / GPU acceleration, good compatibility |
| å®˜æ–¹ transformers | ~405ms/æ¡ | ä¸ä¾èµ– CTranslate2 / No CTranslate2 dependency |

---

## å¸¸è§é—®é¢˜ / FAQ

### 1. CUDA å†…å­˜ä¸è¶³ / CUDA Memory Insufficient

é™ä½ `batch_size` æˆ–é‡å¯ Python è¿›ç¨‹åé‡è¯•ã€‚

Reduce `batch_size` or restart Python process and try again.

### 2. æ¨¡å‹åŠ è½½å¤±è´¥ / Model Loading Failed

æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæ¸…ç†ç¼“å­˜ï¼š

Check model path is correct, clear cache:

```bash
del %LOCALAPPDATA%\huggingface\hub
```

### 3. ç¿»è¯‘ç»“æœå¼‚å¸¸ / Translation Result Abnormal

ç¡®è®¤ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹ç‰ˆæœ¬ / Make sure to use correct model version:
`Derur/nllb-200-3.3B-ct2-float16`

---

## License

MIT
